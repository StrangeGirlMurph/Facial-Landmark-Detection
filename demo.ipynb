{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Facial Landmark Detection - Demonstration\n",
    "Introduction to Deep Learning - Murphy, Aziha, Jonas, Alaa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Before we start let's import the most important libraries\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import cv2 as cv\n",
    "import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For simplicity we will import already preprocessed data from an online source.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import io\n",
    "\n",
    "def loadNumpyArrayFromURL(url):\n",
    "    return np.load(io.BytesIO(requests.get(url).content)).astype(np.float32)\n",
    "\n",
    "# Currently those files are stored in my private google drive.\n",
    "X_train = loadNumpyArrayFromURL(\"https://drive.google.com/uc?id=1wKIgB_Ie_6eqh0-wjqjL8d2eM0j0ys4h\")\n",
    "X_augmented = loadNumpyArrayFromURL(\"https://drive.google.com/uc?id=1d8bEH0jHLK1PlZ-yVcQmvgeLNN-kLlTe\")\n",
    "y_train = loadNumpyArrayFromURL(\"https://drive.google.com/uc?id=1wKHTW9weVAWgudydj6_9FxTaUErl70A3\")\n",
    "y_augmented = loadNumpyArrayFromURL(\"https://drive.google.com/uc?id=1dDACWGT6aImrh-RuAC8vy10VuLduV_XJ\")\n",
    "\n",
    "# The training data should include the augmented data.\n",
    "X_train = np.concatenate((X_train, X_augmented))\n",
    "y_train = np.concatenate((y_train, y_augmented))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset with the augmented data in total consists of 11392 96x96 images and their corresponding labels (15 landmarks with x,y-coordinates each):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((11329, 96, 96, 1), (11329, 30))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keep in mind though that this data is already preprocessed and the labels include filling values (-1). The training data now consists of about 38% of augmented data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelV1 = keras.models.load_model(\"path to model\")\n",
    "modelV2 = keras.models.load_model(\"path to model\")\n",
    "modelV3 = keras.models.load_model(\"path to model\")\n",
    "modelV3.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing the model on labeled data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Labeled Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def testOnDataset(model, data, trueValues=None):\n",
    "    \"\"\"Tests the model on the data and shows the result.\"\"\"\n",
    "    X, Y = predictOnImages(model, data)\n",
    "    fig = plt.figure(figsize=(28, 20), dpi=300)\n",
    "\n",
    "    l = len(data)\n",
    "    i = 1\n",
    "\n",
    "    for im, x, y in zip(data, X, Y):\n",
    "        axis = fig.add_subplot(int(np.ceil(l/5)), 5, i)\n",
    "        axis.imshow(im, cmap='gray')\n",
    "        plt.scatter(x, y, c='b', marker='.')\n",
    "        if trueValues is not None:\n",
    "            plt.scatter(trueValues[i-1][0::2], trueValues[i-1][1::2], c='r', marker='.')\n",
    "        i += 1\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "        \n",
    "def predictOnImages(model, ims):\n",
    "    \"\"\"Predicts on multiple images and returns the list of coordinates of the predicted points.\"\"\"\n",
    "    pred = model.predict(ims)\n",
    "    return ([i[0::2] for i in pred], [i[1::2] for i in pred])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing the model on a webcam input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image utility"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic image utility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mapPointsFromSquareToImage(x, y, c, r, s, w, h):\n",
    "    \"\"\"Maps the points to fit image size and returns them. (The prediction points have their origin in the bottom left corner. But opencv uses the top left corner. Plus the function takes care of the scaling and offset.)\"\"\"\n",
    "    return (x*s/96 + c, (y*s/96) + r)\n",
    "\n",
    "\n",
    "def drawPointsInImage(im, x, y):\n",
    "    \"\"\"Plots the points given by the x and y coordinates on the image and returns it.\"\"\"\n",
    "    size = min(im.shape[:2])//300\n",
    "    for i, j in zip(x, y):\n",
    "        cv.circle(im, (int(i), int(j)), size, (255, 0, 0), -1)\n",
    "    return im\n",
    "\n",
    "\n",
    "def prepareImageForPrediction(im):\n",
    "    \"\"\"Takes an image and returns it ready for prediction (performs: squaring, converting to grayscale and resizing).\"\"\"\n",
    "    return resizeImageToModelSize(grayImage(squareImage(im))).astype(np.float32)\n",
    "\n",
    "\n",
    "def grayImage(im):\n",
    "    \"\"\"Converts the image to grayscale and returns it.\"\"\"\n",
    "    return cv.cvtColor(im, cv.COLOR_BGR2GRAY)\n",
    "\n",
    "\n",
    "def resizeImageToModelSize(im):\n",
    "    \"\"\"Resizes the image to 96x96 and returns it.\"\"\"\n",
    "    return cv.resize(im, (96, 96), interpolation=cv.INTER_AREA).reshape(-1, 96, 96, 1)\n",
    "\n",
    "\n",
    "def mirrorImage(img):\n",
    "    \"\"\"Mirrors the image horizontaly and returns it.\"\"\"\n",
    "    return cv.flip(img, 1)\n",
    "\n",
    "\n",
    "def drawSquareInImage(im, x, y, s, rgb=(179, 255, 179), thickness=3):\n",
    "    \"\"\"Draws a square in the image with the given coordinates (top left corner), width and height and returns it.\"\"\"\n",
    "    cv.rectangle(im, (x, y), (x+s, y+s), rgb, thickness)\n",
    "    return im\n",
    "\n",
    "def squareImage(im):\n",
    "    \"\"\"Squares the image and returns it. (The size is determind by the minimum of width and height of the input.)\"\"\"\n",
    "    h, w = im.shape[:2]\n",
    "    ds = min(h, w)//2\n",
    "    h, w = h//2, w//2   # center\n",
    "    return im[h-ds:h+ds, w-ds:w+ds]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Face recognition with the viola jones algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def violaJonesGetFaceCascade():\n",
    "    \"\"\"Returns the face cascade for the Viola Jones algorithm.\"\"\"\n",
    "    cv2_base_dir = os.path.dirname(os.path.abspath(cv.__file__))\n",
    "    return cv.CascadeClassifier(os.path.join(cv2_base_dir, 'data/haarcascade_frontalface_default.xml'))\n",
    "\n",
    "\n",
    "def violaJones(im, face_cascade):\n",
    "    \"\"\"Performs Viola Jones detection and returns the bounding boxes of the faces.\"\"\"\n",
    "    minSize = 288\n",
    "\n",
    "    faces = face_cascade.detectMultiScale(\n",
    "        im,\n",
    "        scaleFactor=1.1,\n",
    "        minNeighbors=5,\n",
    "        minSize=(minSize, minSize),\n",
    "        flags=cv.CASCADE_SCALE_IMAGE\n",
    "    )\n",
    "\n",
    "    return faces"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Video feed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
